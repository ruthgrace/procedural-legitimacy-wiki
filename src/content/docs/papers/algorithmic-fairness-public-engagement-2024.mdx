---
title: "Procedural Fairness in Algorithmic Decision-Making: The Role of Public Engagement — Leicht-Scholten, Wegner & Decker (2024)"
description: "Procedural Fairness in Algorithmic Decision-Making: The Role of Public Engagement"
---

import { Aside } from '@astrojs/starlight/components';

<Aside type="tip" title="Impact">
**Tier:** Specialized | **Citations:** 26 (Semantic Scholar)
</Aside>

**Authors:** Carmen Leicht-Scholten, Laila Wegner, and Marie Christin Decker

**Published:** 2024, *Ethics and Information Technology*, Vol. 27, No. 1, pp. 1–16

**Domain:** Algorithmic governance, responsible innovation, and public participation

[Google Scholar](https://scholar.google.com/scholar?q=Procedural+Fairness+in+Algorithmic+Decision-Making%3A+The+Role+of+Public+Engagement)

When governments and corporations deploy automated decision-making (ADM) systems that affect people's lives — in hiring, welfare benefits, criminal justice, or urban planning — how should we ensure those systems are procedurally fair? Leicht-Scholten, Wegner, and Decker argue that the dominant approach to algorithmic fairness, which focuses on technical fixes like bias metrics and statistical parity, is insufficient. Technical fairness tools address distributional outcomes (whether different groups receive comparable results) but neglect the procedural dimension: whether affected people had a voice in designing, deploying, and governing the system. The authors contend that genuine procedural fairness in ADM requires structured public engagement, not merely post-hoc auditing or expert oversight.

Drawing on the Responsible Research and Innovation (RRI) framework — particularly its Public Engagement dimension — the paper proposes a model for integrating affected communities into the governance of algorithmic systems. The RRI framework, originally developed for science and technology policy in Europe, emphasizes that innovation processes should be anticipatory, reflective, inclusive, and responsive. The authors argue that these principles map directly onto procedural justice requirements: just as citizens expect fair processes in government decisions, they should expect meaningful participation in the design and oversight of algorithms that shape public outcomes. The paper critiques the current landscape in which ADM systems are developed largely without involving the public or those directly affected, creating what the authors describe as a structural deficit in procedural fairness that no amount of technical debiasing can remedy.

## Background

The paper situates itself at the intersection of AI ethics, science and technology studies (STS), and procedural justice theory. It builds on critiques of the "fairness, accountability, and transparency" (FAccT) movement in computer science, which has made significant progress on distributional fairness metrics but has been slower to integrate participatory and procedural perspectives. The authors also draw on relational justice theories that emphasize the quality of social relations and power dynamics, rather than focusing solely on outcome distributions.

## Key Arguments

| Approach to Algorithmic Fairness | Focus | Procedural Justice Implication |
|---|---|---|
| Technical fairness metrics | Statistical parity, equalized odds, calibration | Addresses distributional outcomes but not process |
| Expert auditing | External review of algorithm performance | Accountability without affected-community voice |
| Transparency/explainability | Making algorithm logic visible | Necessary but not sufficient for procedural fairness |
| Public Engagement (RRI) | Inclusive participation in design and governance | Directly addresses procedural justice deficit |
| Relational justice lens | Power dynamics, recognition, inclusion | Highlights structural barriers to meaningful participation |

## Open Questions

- What institutional structures are needed to make public engagement in algorithmic governance practical and sustainable, rather than a one-time consultation exercise?
- How should public engagement be designed for highly technical systems where meaningful participation requires domain expertise that most citizens lack?
- Can the RRI framework, developed for European science policy contexts, be effectively adapted to algorithmic governance in the Global South or in private-sector contexts?

## Further Reading

- Stilgoe, J., Owen, R., & Macnaghten, P. (2013). "Developing a framework for responsible innovation." *Research Policy*, 42(9), 1568–1580.
- Lee, M. K., Jain, A., Cha, H. J., Ojha, S., & Kusbit, D. (2019). "Procedural justice in algorithmic fairness: Leveraging transparency and outcome control for fair algorithmic mediation." *Proceedings of the ACM on Human-Computer Interaction*, 3(CSCW), 1–26.
- Binns, R. (2018). "Fairness in machine learning: Lessons from political philosophy." *Proceedings of the 2018 Conference on Fairness, Accountability, and Transparency*, 149–159.
