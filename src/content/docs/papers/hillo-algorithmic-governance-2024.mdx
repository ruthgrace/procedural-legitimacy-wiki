---
title: "Algorithmic Governance: Experimental Evidence on Citizens' and Public Administrators' Legitimacy Perceptions of Automated Decision-Making — Hillo, Vento & Erkkila (2025)"
description: "Algorithmic Governance: Experimental Evidence on Citizens' and Public Administrators' Legitimacy Perceptions of Automated Decision-Making"
---

import { Aside } from '@astrojs/starlight/components';

<Aside type="tip" title="Impact">
**Tier:** Specialized | **Citations:** 3 (Semantic Scholar)
</Aside>

**Authors:** Jaakko Hillo, Isak Vento, and Tero Erkkila

**Published:** 2025, *Public Administration*, pp. 1–16 (online first), DOI: 10.1111/padm.70028

**Domain:** Algorithmic governance, legitimacy perceptions, and public administration (Finland)

[Google Scholar](https://scholar.google.com/scholar?q=Algorithmic+Governance%3A+Experimental+Evidence+on+Citizens%27+and+Public+Administrators%27+Legitimacy+Perceptions+of+Automated+Decision-Making)

As governments increasingly adopt algorithmic and AI-based tools to make or support decisions, a fundamental legitimacy question arises: do citizens and public administrators actually perceive automated decision-making as legitimate? Hillo, Vento, and Erkkila address this through randomized survey experiments conducted with both Finnish top-level public administrators (N = 842) and a nationally representative sample of citizens (N = 3,245). Their experimental design varies two key features of algorithmic decision-making — transparency (whether the algorithm's logic is explained) and human discretion (whether a human official retains decision-making authority) — in the context of child protection services.

The results show that both transparency and human discretion significantly enhance perceived legitimacy of automated decisions. When the algorithm's reasoning is made transparent and when human officials retain meaningful oversight, both citizens and administrators are more accepting of algorithmic governance. Crucially, however, the treatment effects are larger among public administrators than among citizens. Administrators are more sensitive to procedural features like transparency and human control — perhaps because they understand the institutional stakes of automation more acutely. This elite-mass divergence has important implications: if administrators and citizens weight procedural safeguards differently, there may be a gap between the algorithmic governance arrangements that administrators design and the legitimacy expectations that citizens hold.

## Background

The study is situated within the growing literature on algorithmic governance and public sector automation, drawing on legitimacy theory from political science and public administration. The experimental design follows a 2x2 factorial structure (transparency vs. no transparency; human discretion vs. full automation) embedded in a vignette about child protection case assessment. The choice of child protection as the decision context is deliberate — it represents a high-stakes, emotionally charged domain where questions of algorithmic legitimacy are especially salient.

## Key Arguments

| Experimental Condition | Effect on Citizens | Effect on Administrators |
|---|---|---|
| Algorithmic transparency present | Increased perceived legitimacy | Larger increase in perceived legitimacy |
| No algorithmic transparency | Lower perceived legitimacy | Significantly lower perceived legitimacy |
| Human discretion retained | Increased perceived legitimacy | Larger increase in perceived legitimacy |
| Fully automated (no human discretion) | Lower perceived legitimacy | Significantly lower perceived legitimacy |
| Elite-mass gap | Citizens less sensitive to procedural features | Administrators more responsive to transparency and oversight cues |

## Open Questions

- Does the elite-mass gap in legitimacy perceptions hold in other national contexts, or is it specific to Finland's high-trust institutional environment?
- How would legitimacy perceptions change in lower-stakes decision domains (e.g., routine permit processing) versus other high-stakes domains (e.g., criminal sentencing)?
- Can participatory approaches to algorithm design — such as involving citizens in defining decision criteria — close the legitimacy gap more effectively than transparency alone?

## Further Reading

- Grimmelikhuijsen, S., Jilke, S., Olsen, A. L., & Tummers, L. (2017). "Behavioral public administration: Combining insights from public administration and psychology." *Public Administration Review*, 77(1), 45–56. See also the [wiki entry on Grimmelikhuijsen et al. (2021)](/procedural-legitimacy-wiki/papers/grimmelikhuijsen-et-al-2021/).
- Bullock, J. B. (2019). "Artificial intelligence, discretion, and bureaucracy." *American Review of Public Administration*, 49(7), 751–761.
- Veale, M., & Brass, I. (2019). "Administration by algorithm? Public management meets public sector machine learning." In K. Yeung & M. Lodge (Eds.), *Algorithmic Regulation*. Oxford University Press.
